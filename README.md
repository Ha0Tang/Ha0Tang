![github stats](https://github-readme-stats.vercel.app/api?username=Ha0Tang&show_icons=true)

![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=Ha0Tang)

## Hao Tang
_**[[Homepage](http://disi.unitn.it/~hao.tang/)] [[Google Scholar](https://scholar.google.com/citations?user=9zJkeEMAAAAJ&hl=en)] [[Twitter](https://twitter.com/HaoTang_ai)]**_

<!-- _**I am currently a postdoctoral researcher at Computer Vision Lab, ETH Zurich, Switzerland.**_ -->
_**I am currently a postdoctoral researcher at Computer Vision Lab, ETH Zurich, Switzerland.**_

## âš¡  **News**
**We released the code of [XingVTON](https://github.com/Ha0Tang/XingVTON) and [CIT](https://github.com/Amazingren/CIT) for virtual try-on, the code of [TransDA](https://github.com/ygjwd12345/TransDA) for source-free domain adaptation using Transformer, the code of [IEPGAN](https://github.com/mikecheninoulu/Unsupervised_IEPGAN) for 3D pose transfer, the code of [TransDepth](https://github.com/ygjwd12345/TransDepth) for monocular depth prediction using Transformer, the code [GLANet](https://github.com/ygjwd12345/GLANet) for unpaired image-to-image translation, the code [MHFormer](https://github.com/Vegetebird/MHFormer) for 3D human pose estimation.**

## ðŸŒ± **My Repositories**
### 3D Human Pose Estimation
- **[MHFormer](https://github.com/Vegetebird/MHFormer)** (CVPR 2022)

### Text-to-Image Synthesis
- **[DF-GAN](https://github.com/tobran/DF-GAN)** (CVPR 2022 Oral)
- **[PPE](https://github.com/zipengxuc/PPE)** (CVPR 2022)

### 3D Objection Generation
- **[CGT](https://github.com/mikecheninoulu/CGT)** (AAAI 2022)
- **[IEPGAN](https://github.com/mikecheninoulu/Unsupervised_IEPGAN)** (ICCV 2021)
- **[AniFormer](https://github.com/mikecheninoulu/AniFormer)** (BMVC 2021)

### Monocular Depth Prediction
- **[TransDepth](https://github.com/ygjwd12345/TransDepth)** (ICCV 2021)
- **[StructuredAttention](https://github.com/danxuhk/StructuredAttentionDepthEstimation)** (CVPR 2018 Spotlight)

### Face Anonymisation
- **[AnonyGAN](https://github.com/Fodark/anonygan)** (ICIAP 2021)

### Person Image Generation 
- **[XingGAN](https://github.com/Ha0Tang/XingGAN)** (ECCV 2020)
- **[BiGraphGAN](https://github.com/Ha0Tang/BiGraphGAN)** (BMVC 2020 Oral)
- **[C2GAN](https://github.com/Ha0Tang/C2GAN)** (ACM MM 2019 Oral)
- **[GestureGAN](https://github.com/Ha0Tang/GestureGAN)** (ACM MM 2018 Oral & Best Paper Candidate)

### Scene Image Generation
- **[LGGAN](https://github.com/Ha0Tang/LGGAN)** (CVPR 2020)
- **[DAGAN](https://github.com/Ha0Tang/DAGAN)** (ACM MM 2020)
- **[DPGAN](https://github.com/Ha0Tang/DPGAN)** (TIP 2021)
- **[SelectionGAN](https://github.com/Ha0Tang/SelectionGAN)** (CVPR 2019 Oral)
- **[CrossMLP](https://github.com/Amazingren/CrossMLP)** (BMVC 2021 Oral)
- **[EdgeGAN](https://github.com/Ha0Tang/EdgeGAN)**
- **[PanoGAN](https://github.com/sswuai/PanoGAN)** (TMM 2022)

### Unsupervised Image Translation
- **[GLANet](https://github.com/ygjwd12345/GLANet)**
- **[AttentionGAN](https://github.com/Ha0Tang/AttentionGAN)** (IJCNN 2019 Oralï¼‰
- **[GazeAnimation](https://github.com/zhangqianhui/GazeAnimation)** (ACM MM 2020)
- **[AsymmetricGAN](https://github.com/Ha0Tang/AsymmetricGAN)** (ACCV 2018 Oral)

### Deep Dictionary Learning
- **[DDLCN](https://github.com/Ha0Tang/DDLCN)** (WACV 2019 Oral)

### Virtual Try-On
- **[XingVTON](https://github.com/Ha0Tang/XingVTON)**
- **[CIT](https://github.com/Amazingren/CIT)**

### Hand Gesture Recognition
- **[HandGestureRecognition](https://github.com/Ha0Tang/HandGestureRecognition)** (Neurocomputing 2019)

### Source-Free Domain Adaptation
- **[TransDA](https://github.com/ygjwd12345/TransDA)**
